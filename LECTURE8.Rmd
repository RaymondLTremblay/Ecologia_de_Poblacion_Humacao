---
title: "Stochasticity and Uncertainty"
author: "NRES 470/670"
date: "Feb 12, 2017"
output: 
  html_document: 
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

![](uncertainty1.png)

## Uncertainty!

All ecological systems are full of uncertainty. We all know it intuitively. But what *exactly* do we mean by that? And how can we deal with it? How can we incorporate it into our models? 

This is probably one of the most important modules in this course. But it is not in the Gotelli book, nor is it in most ecology textbooks.

### A taxonomy of uncertainty

There are two major reasons we can be uncertain. Either we _lack sufficient knowledge_ or the _system itself is variable and unpredictable_. Let's explore these two types of uncertainty.

- **You lack sufficient knowledge**. This is also known variously as *sampling uncertainty*, parameter uncertainty, structural uncertainty, and more. If you collected more data you could in principle make a better model that more closely represents reality.

- **The system is inherently unpredictable**. This is also known as **randomness** or **stochasticity**. No matter how much we study a coin, we will not be able to predict outcome of a coin flip any better than 50-50 (at least let's just say that's the case for now). Ecological systems have inherent variability. We can't predict with certainty whether or not an individual will mate, or die. We can't really even be certain whether next year or the year after that will be a good year or a bad year for offspring production or mortality in general!

## How to deal with uncertainty
The key is to **embrace uncertainty**. As population ecologists, we have three major tools to help us manage and account for uncertainty in our study systems:

1. First, what if we simply don't have enough data to build a perfect model? This is an example of *lacking sufficient knowledge*. In this case, the tool we use is called **sensitivity analysis**. Basically, we try all plausible values and see what happens to our study system (e.g., does the population go extinct? decline?). 

2. Second, we usually can't predict whether an individual will live or die, breed or not breed (whether an individual will "get lucky" so to speak!)? We might know the per-capita *probability* of breeding, or the *probability* of dying, or the per-capita *rate* of offspring production, or the probability of a given offspring being female. But when it comes to projecting who lives and dies, who gives birth and who doesn't, how many females are born, we _just can't know for sure_. This is an example of a system being *inherently unpredictable*. In population ecology this is called **demographic stochasticity**. In this case, the tool we use is **computer-simulated "coin flipping"**.

3. Third, we usually can't predict whether next year or the year after will be a good one or a bad one- that is, whether the vital rates will be more or less optimal year-to-year (whether a _population_ will "get lucky", so to speak). In population ecology this is called **environmental Stochasticity**. In this case, the tool we use is **randomly varying vital-rates**. 

![](dice1.png)

## Random number generation
To incorporate uncertainty and randomness into our models, we need to include *stochastic* components so that each model run (replicate) -- or each year of each model run -- is different from one another. That is, we need to include at least one **random number generator** in our models! A random number generator is like a box of (potentially infinite) possible numbers -- a lottery ball machine for example! Each time we want a new number we reach in and pull one out, record the number, put it back in and shake it up again.

![](lottery1.png)


Every random-number generator has a **distribution**. This is a way of defining what exactly is in the box. For example, the box might have 10 "ones", 5 "twos", and 2 "threes". In this case the distribution looks like this (*probability* of each *possibility*):

```{r echo=FALSE}
box <- c(rep(1,10),rep(2,5),rep(3,2))
barplot(table(box)/sum(table(box)),ylab="probability",xlab="possibility")

```


A probability distribution can be pretty much anything you want it to be. However, there are several key distributions that come up again and again in nature, and we should know them!


### Probability distributions

### Discrete vs. continuous
In *discrete distributions*, each outcome has a specific probability (like the probability of flipping a coin 10 times and getting 4 heads). For example, let's consider the *binomial distribution*  

```{r echo=FALSE}
#rbinom(10,10,0.3)    # the random numbers have no decimal component

             # plot a discrete distribution!
xvals <- seq(0,10,1)
probs <- dbinom(xvals,10,prob=0.3)
names(probs) <- xvals
               
barplot(probs,ylab="Probability",xlab="Possibilities",main="Binomial distribution (discrete)")

#barplot(cumsum(probs),ylab="Cumulative Probability",main="Binomial distribution (discrete)")   # cumulative distribution

#sum(probs)   # just to make sure it sums to 1!  Does it??? 

```


Another discrete distribution we will use in this class is the *Poisson distribution*:

```{r echo=FALSE}

             # plot a discrete distribution!
xvals <- seq(0,10,1)
probs <- dpois(xvals,lambda=2.2)
names(probs) <- xvals
               
barplot(probs,ylab="Probability",xlab="Possibilities",main="Poisson distribution (discrete)")


```


In *continuous distributions*, there is an infinite set of possibilities in our random-number box.  

Let's consider the *uniform distribution*: 

```{r}

lower = 0
upper = 10

curve(dunif(x,lower,upper),0,10,ylab="Probability (density)",xlab="Possibilities",main="Uniform distribution (continuous)",ylim=c(0,1))   # probability density

```

This isn't a very intersting looking distribution. All possible numbers from 0 to 10 are equally probable.


Another continuous distribution you should know is called the *Normal distribution*.

```{r}
mean = 7.1
stdev = 1.9

curve(dnorm(x,mean,stdev),0,15,ylab="Probability (density)",xlab="Possibilities",main="Normal distribution (continuous)")   # probability density

```


### In-Class Exercise: Stochasticity and Uncertainty

These concepts (like everything in this class) are best understood by worked examples.

Let's start with a basic exponentially growing population that looks something like this:


![](IM10.jpg)

#### _Parameter Uncertainty_    

1. Set *Birth rate* equal to 0.4 and *Death rate* equal to 0.3. Set initial abundance at 10. Under the "Settings" menu set the model to run for 10 years. Make sure your *Population* stock can not go negative (in the ). Hit "Simulate"- you should see exponential growth! 

2. **Parameter uncertainty:** What if we have imperfect knowledge about birth rate. The birth rate could be anything from 0.2 to 0.5. Run the model with the lowest and the highest possible birth rate. 

3. Now use the "Compare Results" tool (under the "Tools" menu in the upper right corner...) to visualize the range of possible population growth trajectories that would be possible given our *uncertainty* about birth rate. 

**Q** What is the range of possible final abundances after 10 years? 


#### _Demographic Stochasticity_  

1. Set *Birth rate* back to 0.4. Hit "Simulate"- make sure you still see exponential growth!   
2. We will use a *Binomial distribution* to represent the number of mortalities. That is, we flip a coin the same number of times as there are individuals in the population. If the coin comes up heads, then the individual dies. In this case we are using a biased coin- it only comes up heads 30% of the time! The *Binomial distribution* essentially represents the number of times heads came up. To do this in InsightMaker, use the following formula for the *Deaths* flow:

```
RandBinomial([Population], [Death rate])
```

In plain english: the number of deaths is equal to the number of "coin flips" that come out heads if the probability of getting heads is equal to [Death rate]. 


For the birth rate, we will use the *Poisson* distribution. The Poisson distribution is often use to represent births, because there could feasibly be more births than there are individuals currently in the population (e.g., if all individuals have two offspring!). However, the maximum number of "heads" is the total number of individuals. To do this in InsightMaker, use the following formula for the *Births* flow:

```
RandPoisson([Population]*[Birth rate])
```
In plain english: the number of births is a Poisson-distributed random number with mean equal to [Population]*[Birth rate].

3. Run the simulation. What does it look like?
4. Use the "Sensitivity Testing" tool (in the "Tools" menu, upper right corner) to run the model 50 times. Choose [Population] as the "Monitored Primitive".
5. Change the initial abundance to 500 and re-run the "Sensitivity Testing" tool.

**Q** Is the effect of demographic stochasticity bigger at low or high abundances?

#### _Environmental Stochasticity_  

1. Set *Births* back to what it was before ([Population]*[Birth rate]), and do the same for *Deaths*.
2. We will use a *Normal distribution* to represent how the birth rate changes each year. This could represent climatic variablity -- "good years" and "bad years". The *Normal distribution* is commonly used for this type of variability- it is characterized by an average value (**mean**) and a variability measure (**standard deviation**). To do this in InsightMaker, use the following formula for the *Birth Rate* variable:

```
RandNormal(0.4, 0.4)
```

Similarly, use the following formula for the *Birth Rate* variable:

```
RandNormal(0.3, 0.3)
```

3. Use the "Sensitivity Testing" tool (in the "Tools" menu, upper right corner) to run the model 50 times. Choose [Population] as the "Monitored Primitive".

5. Change the initial abundance to 500 and re-run the "Sensitivity Testing" tool.

**Q** Is the effect of environmental stochasticity bigger at low or high abundances?


[--go to next lecture--](LECTURE9.html)
























