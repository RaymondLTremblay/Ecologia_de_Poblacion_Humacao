---
title: "Stochasticity and Uncertainty"
author: "NRES 470/670"
date: "Feb 20, 2018"
output: 
  html_document: 
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

![](uncertainty2.jpg)

## Uncertainty!

All ecological systems are full of uncertainty. We all know it intuitively. But what *exactly* do we mean by that? And how can we deal with it? How can we incorporate it into our models? 

This is one of the most important modules in this course. But it is not in the Gotelli book, nor is it in highlighted in most ecology textbooks.

### A taxonomy of uncertainty

There are two major reasons we can be uncertain. Either we _lack sufficient knowledge_ or the _system itself is variable and unpredictable_. Let's explore these two types of uncertainty.

- **You lack sufficient knowledge**. This is also known variously as *sampling uncertainty*, parameter uncertainty, structural uncertainty, and more. If you collected more data you could in principle make a better model that more closely represents reality.

- **The system is inherently unpredictable**. This is also known as **randomness** or **stochasticity**. No matter how much we study a coin, we will not be able to predict outcome of a coin flip any better than 50-50 (at least for a proper coin flip!). Ecological systems have inherent variability. We can't predict with certainty whether or not an individual will mate, or die. We can't really even be certain whether next year or the year after that will be a good year or a bad year for offspring production or mortality in general!

## How to deal with uncertainty
The key is to **embrace uncertainty**. As population ecologists, we have three major tools to help us manage and account for uncertainty in our study systems:

### Uncertainty analysis

1. First, what if we simply don't have enough data to build a perfect model? This is an example of *lacking sufficient knowledge*. In this case, the tool we use is called **uncertainty analysis**. Basically, we try all plausible values (or just the minimum and maximum value) and see what happens to our study system (e.g., does the population go extinct? decline?). You should know -- the term "sensitivity analysis" is often used for this concept, but InsightMaker uses this term in a different way (basically referring to multiple replicates of stochastic models) -- so we will refer to this as "uncertainty analysis" to avoid confusion)

### Stochastic models (two main types)

2. Second, we usually can't predict whether an individual will live or die, breed or not breed (whether an individual will "get lucky" so to speak!)? We might know the per-capita *probability* of breeding, or the *probability* of dying, or the per-capita *rate* of offspring production, or the probability of a given offspring being female. But when it comes to projecting who lives and dies, who gives birth and who doesn't, how many females are born, we _just can't know for sure_. This is an example of a system being inherently unpredictable. In population ecology this is called **demographic stochasticity**. In this case, the tool we use is **computer-simulated "coin flipping"**.

3. Third, we usually can't predict whether next year or the year after will be a good one or a bad one for a population- that is, whether the per-capita vital rates (e.g., $b$, or $d$ or $r$) will be more or less optimal year-to-year (whether a _population_ will "get lucky", so to speak). This is another example of a system being *inherently unpredictable*. In population ecology this is called **environmental stochasticity**. In this case, the tool we use is **randomly varying vital rates**. 

![](dice1.png)

## Random number generation
To incorporate uncertainty and randomness into our models, we need to include *stochastic* components so that each model run (replicate) -- or each year of each model run -- is different from one another. That is, we need to include at least one **random number generator** in our models! A random number generator is like a box of (potentially infinite) possible numbers -- a lottery ball machine for example! Each time we want a new number we reach in and pull one out, record the number, put it back in and shake it up again.

![](lottery1.png)


Every random-number generator has a **distribution**. This is a way of defining what exactly is in the box. For example, the box might have 10 "ones", 5 "twos", and 2 "threes". In this case the distribution looks like this (*probability* of each *possibility*):

```{r echo=FALSE}
box <- c(rep(1,10),rep(2,5),rep(3,2))
barplot(table(box)/sum(table(box)),ylab="probability",xlab="possibility")

```


A probability distribution can be pretty much anything you want it to be. However, there are several key distributions that come up again and again, and we should know them!

### Probability distributions

### Discrete vs. continuous
In *discrete distributions*, each unique outcome has a specific probability (like the probability of flipping a coin 10 times and getting 4 heads). For example, let's consider a *binomial distribution*  

```{r echo=FALSE}
#rbinom(10,10,0.3)    # the random numbers have no decimal component

             # plot a discrete distribution!
xvals <- seq(0,10,1)
probs <- dbinom(xvals,10,prob=0.3)
names(probs) <- xvals
               
barplot(probs,ylab="Probability",xlab="Possibilities",main="Binomial distribution (discrete)")

#barplot(cumsum(probs),ylab="Cumulative Probability",main="Binomial distribution (discrete)")   # cumulative distribution

#sum(probs)   # just to make sure it sums to 1!  Does it??? 

```


Another discrete distribution we will use in this class is the *Poisson distribution*:

```{r echo=FALSE}

             # plot a discrete distribution!
xvals <- seq(0,10,1)
probs <- dpois(xvals,lambda=2.2)
names(probs) <- xvals
               
barplot(probs,ylab="Probability",xlab="Possibilities",main="Poisson distribution (discrete)")


```


In *continuous distributions*, there are an infinite number of possibilities between any two unique possibilities.  

Let's consider the *uniform distribution*: 

```{r}

lower = 0
upper = 10

curve(dunif(x,lower,upper),0,10,ylab="Probability (density)",xlab="Possibilities",main="Uniform distribution (continuous)",ylim=c(0,1))   # probability density

```

This isn't a very intersting looking distribution. All possible numbers from 0 to 10 are equally probable.

Another continuous distribution you should know is called the *Normal distribution*. This distribution has a lower bound of $-\infty$ and an upper bound of $\infty$.

**Q** What population parameter might this distribution be useful for modeling?

```{r}
mean = 7.1
stdev = 1.9

curve(dnorm(x,mean,stdev),0,15,ylab="Probability (density)",xlab="Possibilities",main="Normal distribution (continuous)")   # probability density

```

Another continuous distribution you should know is called the *Lognormal distribution*. This distribution has a lower bound of zero and an upper bound of $\infty$.

**Q** What population parameter might this distribution be useful for modeling?

```{r}
meanlog = 1.4
stdevlog = 0.6

curve(dlnorm(x,meanlog,stdevlog),0,15,ylab="Probability (density)",xlab="Possibilities",main="Lognormal distribution (continuous)")   # probability density

```

Another continuous distribution you should know is called the *Beta distribution*. This distribution has a lower bound of zero and an upper bound of 1.

**Q** What population parameter might this distribution be useful for modeling?

```{r}
shape1 = 10
shape2 = 4

curve(dbeta(x,shape1,shape2),0,1,ylab="Probability (density)",xlab="Possibilities",main="Beta distribution (continuous)")   # probability density

```

### Explore distributions in R

Let's play around with distributions a little using R.

Note that all these distributions are also available to you in InsightMaker. 

Here's some R syntax for you!

Note that R random number generators start with the letter "r" -- for "random".

The first *argument* represents how many random numbers you want R to draw from the specified distribution.

The following arguments represent the *parameters* of the random distribution you wish to draw from. 

```{r eval=F}
### Binomial random number generator
rbinom(1,size=10,prob=0.5)    # note: "size" is the number of coin flips, and "prob" is the probability of coming up heads

### Poisson random number generator
rpois(1,lambda=4.1)     # note: "lambda" represents the poisson mean (and variance!)

### Uniform random number generator
runif(1,min=1,max=3.5)   # "min" and "max" are pretty obvious!

### Normal random number generator
rnorm(1,mean=3,sd=4.1)   # normal distribution is defined by "mean" and "sd" (standard deviation).

### lognormal random number generator (like normal distribution, but can not go below zero)
rlnorm(1,meanlog=0.5,sdlog=0.2)    # lognormal distribution is defined by "meanlog", the mean of the log-transformed random variable and "sd" (standard deviation of the log-transformed random variable).

### beta random number generator (bounded between 0 and 1- just like survival rate!)
rbeta(1,shape1=10,shape2=3)  # beta distribution is defined by "shape1" and "shape2", which together define the mean and spread within the range from 0 to 1.

```

You can even make up your own distribution if you want!

```{r}
distribution <- c(5,3,5,4,3,6,4,5,5,1,6,5,4,3,6,6,4,2,8,4,4,5,2)
hist(distribution,freq = F, ylab="Probability",xlab="Possibilities")  # visualize distribution
sample(distribution,1)  # take one random sample from this distribution!
```


### In-Class Exercise: Fit a distribution! 

```{r echo=FALSE, eval=FALSE}
hist(rgamma(20,4.1,2))

```

![](canvasback1.jpg)

Let's imagine we have studied a population of canvasback ducks over a 20 year period and we have estimated the average number of eggs successfully hatched per female for each of the 20 years. 

We first enter these numbers into R and visualize the distribution:

```{r}
hatch_perfem <- c(3.05, 1.45, 0.99, 3.24, 1.49, 1.70, 1.66, 2.32, 0.83, 2.41,
2.33, 1.68, 1.43, 2.74, 2.05, 3.13, 1.90, 3.69, 1.55, 2.79)

hist(hatch_perfem)

```

**Q**: what type of uncertainty does this set of values most likely represent?

**Q**: what distribution might we use to fit this distribution?

Now let's try to fit a distribution to these data! Because the total per-capita number of eggs successfully hatched cannot go below zero (but has no defined upper bound) let's try to fit a lognormal distribution!

We could use statistics to fit the distribution, but we are just going to use trial and error. Here is some code to help you get started.

Note that the lognormal distribution has two parameters: the first (meanlog) helps to define the mean and the other (sdlog) helps to determine the variability of the distribution. 

```{r}

## first, plot a histogram of the data from the 20-year study
hist(hatch_perfem,freq=F,main="Histogram of avg number hatched per female",xlab="possibilities",ylab="probability",xlim=c(0,10),ylim=c(0,1))

## now, overlay a lognormal probability distribution with arbitrary parameters (meanlog and sdlog)

curve(dlnorm(x,meanlog=1.5,sdlog=0.2),col="green",lty=2,lwd=2,add=T)


```

1) Use trial-and-error to find appropriate parameters for the lognormal distribution.

2) Use your fitted distribution to predict the average number of hatchlings per female for the next 5 years. To do this, use the "rlnorm" function in R.



### In-Class Exercise 2: Stochasticity and Uncertainty in InsightMaker

These concepts (like everything in this class) are best understood by worked examples.

Let's start with a basic exponentially growing population that looks something like this:


![](IM10.jpg)

#### _Parameter Uncertainty_    

1. Set *Birth rate* equal to 0.4 and *Death rate* equal to 0.3. Set initial abundance at 10. Under the "Settings" menu set the model to run for 10 years. Make sure your *Population* stock can not go negative (this is a setting in the configurations panel). Hit "Simulate"- you should see exponential growth! 

2. **Parameter uncertainty:** What if we have imperfect knowledge about birth rate? The birth rate could be anything from 0.2 to 0.5. Run the model with the lowest and the highest possible birth rate. 

3. Now use the "Compare Results" tool (under the "Tools" menu in the upper right corner...) to visualize the range of possible population growth trajectories that would be possible given our *uncertainty* about birth rate. 

**Q** What is the range of possible final abundances after 10 years? 

**Q** Should we study this system more if we want to know whether the population is growing or declining?? 

#### _Demographic Stochasticity_  

1. Set *Birth rate* back to 0.4. Hit "Simulate"- make sure you still see exponential growth!

2. We will use a *Binomial distribution* to represent the number of mortalities. That is, we _flip a coin the same number of times as there are individuals in the population_. If the coin comes up heads, then the individual dies. In this case we are using a biased coin- it only comes up heads 30% of the time! The *Binomial distribution* essentially represents the number of times heads came up. To do this in InsightMaker, use the following formula for the *Deaths* flow:

```
RandBinomial([Population], [Death rate])
```

In plain english: the number of deaths is equal to the number of "coin flips" that come out heads if the probability of getting heads is equal to [Death rate] and the number of flips is equal to [Abundance]. 

For the total births, $B$ we will use the *Poisson* distribution. The Poisson distribution is often use to represent births, because there could feasibly be more births than there are individuals currently in the population (e.g., if all individuals have two offspring!). This would not be possible with a binomial distribution! That is, the maximum number of "heads" (you can always think of binomial distributions as coin-flipping!) is the total number of individuals. 

To do this in InsightMaker, use the following formula for the *Births* flow:

```
RandPoisson([Population]*[Birth rate])
```
In plain english: the number of births is a random draw from a Poisson random number generator with mean equal to the expected number of births ([Population]*[Birth rate]).

3. Run the simulation. What does it look like?

4. Use the "Sensitivity Testing" tool (in the "Tools" menu, upper right corner) to run the model 50 times. Choose [Population] as the "Monitored Primitive".

5. Change the initial abundance to 500 and re-run the "Sensitivity Testing" tool.

**Q** Is the effect of *demographic stochasticity* bigger at low or high abundances?

#### _Environmental Stochasticity_  

1. Set *Births* back to what it was before ([Population]x[Birth rate]), and do the same for *Deaths*.
2. We will use a *Normal distribution* to represent how the birth rate changes each year. This could represent climatic variablity -- "good years" and "bad years". The *Normal distribution* is commonly used for this type of variability- it is characterized by an average value (**mean**) and a variability measure (**standard deviation**). To do this in InsightMaker, use the following formula for the *Birth Rate* variable:

```
RandNormal(0.4, 0.4)
```

Similarly, use the following formula for the *Death Rate* variable:

```
RandNormal(0.3, 0.3)
```

3. Use the "Sensitivity Testing" tool (in the "Tools" menu, upper right corner) to run the model 50 times. Choose [Population] as the "Monitored Primitive".

5. Change the initial abundance to 500 and re-run the "Sensitivity Testing" tool.

**Q** Is the effect of *environmental stochasticity* bigger at low or high abundances?

6. Note that the normal distribution CAN go below zero or above 1, which is not always biologically realistic! However, as we have seen before, InsightMaker does not allow a [Flow In] to remove from a [Stock] or a [Flow Out] to add to a [Stock], so we don't really need to worry about this problem! That is, InsightMaker will *truncate* the normal distribution for us. Alternatively (if we want to be very explicit) we could just **truncate** the normal distribution ourselves. That is, if the random number you draw comes out below zero, just make it zero! 

For birth rate, this can be done like this:

```
Max(0,RandNormal(0.4, 0.4))
```

**Q** Can you implement a **catastrophe** scenario? That is, make a scenario where there is a low probability of an event (e.g., flood, disease, drought) that causes very high mortality and/or very low birth rate?  

A catastrophe can be implemented by using an IF-THEN statement: if the random number is below some rare value (e.g., 0.05) then cause a catastrophe to occur! 

Hint: You may want to use an IF-THEN-ELSE statement to do this... The most basic (most commonly used) random number generator draws numbers from a *uniform* distribution with a minimum of 0 and a maximum of 1. To do this in InsightMaker, you can use this syntax:

```
Rand(0, 1)
```


**Q** What if environmental stochasticity influences survival and fecundity in the same manner? That is: what if a "good year" for births is also a good year for survival? Would this increase or decrease the effect of environmental stochasticity on population dynamics? In InsightMaker, try to impement a scenario where the environmental stochasticity in survival rate is perfectly **correlated** with environmental stochasticity in birth rate. 


Hint: you will need another [variable] in your InsightMaker canvas- this variable could be named something like "Habitat Quality", and should store a random draw from a Normal distribution with mean "0" and standard deviation "1":

```
RandNormal(0, 1)
```

Next, you can alter your per-capita fecundity parameter to have the following syntax, which would represent a mean fecundity of 0.85 with a standard deviation of 0.4

```
0.85+0.4*[habitat quality]
```


**Q** Under what circumstances can you envision small populations being more vulnerable to environmental stochasticity than large populations?


[--go to next lecture--](LECTURE9.html)
























